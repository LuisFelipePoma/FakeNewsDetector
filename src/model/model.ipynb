{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh1SOqFVyuPo"
      },
      "source": [
        "# Análisis de datos exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Se debe ejecutar despúes del notebook `data.ipynb`\n",
        "- Este notebook crea el archivo necesario para `export.ipynb`\n",
        "- Los archivos generados son:\n",
        "  - `model.h5`: Modelo de red neuronal (Este archivo es necesario para predecir las new entrantes la app web `./client`)\n",
        "- Es necesario [descargar](https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt) el modelo de Glove de 100 dimensiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juw3GXrVyuPp"
      },
      "source": [
        "## Cargar datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Eh75So8yuPq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"200k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "evNpSbVeyuPs",
        "outputId": "86460e6e-f786-4f72-b852-e0a929c87211"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmuowRWiyuPs",
        "outputId": "48ea296c-4a30-4779-89f8-20af101eae22"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89c29vbJyuPw"
      },
      "source": [
        "## Cargando el modelo de Word Embedding (Glove 100d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el modelo de glove\n",
        "def load_glove_model(file_path):\n",
        "    \"\"\"Cargar un modelo GloVe desde un archivo de texto.\"\"\"\n",
        "    model = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        # Parsear el archivo .txt\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = [float(value) for value in values[1:]]\n",
        "            model[word] = vector\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calcular la similitud coseno entre dos vectores.\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
        "    return similarity\n",
        "\n",
        "def most_similar_words(word, model, top_n=5):\n",
        "    \"\"\"Encontrar las palabras más similares a la palabra dada en el modelo.\"\"\"\n",
        "    if word not in model:\n",
        "        print(f\"La palabra '{word}' no está en el modelo.\")\n",
        "        return []\n",
        "\n",
        "    word_vector = model[word]\n",
        "    similarities = []\n",
        "\n",
        "    for other_word, other_vector in model.items():\n",
        "        if other_word != word:\n",
        "            similarity = cosine_similarity(word_vector, other_vector)\n",
        "            similarities.append((other_word, similarity))\n",
        "\n",
        "    # Ordenar por similitud descendente\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Devolver las palabras más similares (top_n)\n",
        "    return similarities[:top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ruta al archivo GloVe\n",
        "glove_file_path = 'glove.6B.100d.txt'\n",
        "\n",
        "# Cargar el modelo GloVe\n",
        "embedding_index = load_glove_model(glove_file_path)\n",
        "\n",
        "# Ejemplo de uso con la palabra 'ate'\n",
        "word_to_lookup = 'ate'\n",
        "similar_words = most_similar_words(word_to_lookup, embedding_index, top_n=10)\n",
        "\n",
        "print(f\"Palabras más similares a '{word_to_lookup}':\")\n",
        "for similar_word, similarity in similar_words:\n",
        "    print(f\"{similar_word}: {similarity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creacion del Word Embedding en base a nuestros datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['features'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
>>>>>>> 4146da4b1e02624e826b96e84373a0310a205e6d
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variables para el modelo\n",
        "vocab_size = 50000 # Número máximo de palabras a utilizar\n",
        "max_sequence_length = 300 # Número máximo de palabras en una secuencia\n",
        "embedding_dim = 100 # Dimensión del vector de embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenizar la data (BOW)\n",
        "tokenizer = Tokenizer(num_words=vocab_size)  # Instanciamos el tokenizer\n",
        "tokenizer.fit_on_texts(df[\"features\"])  # convert to string type\n",
        "\n",
        "# Obtenemos solo las primeras 10000 palabras\n",
        "# tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= vocab_size}\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Observamos el tamaño del vocabulario\n",
        "vocab_size = len(word_index)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Invertimos el vocabulario\n",
        "inv_map = {v: k for k, v in tokenizer.index_word.items()}\n",
        "\n",
        "# Guarda el vocabulario invertido en un archivo JSON\n",
        "with open('vocab.json', 'w') as archivo:\n",
        "    json.dump(inv_map, archivo)\n",
        "\n",
        "# El vocabulario es guardado para posteriormente ser usado en clasificacion usando web scrapping\n",
        "print(f'Vocabulario invertido guardado en `vocab.json`')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertimos las palabras en secuencias de números\n",
        "sequences = tokenizer.texts_to_sequences(df[\"features\"])\n",
        "\n",
        "# Aplicamos padding a las secuencias\n",
        "padded_seq = pad_sequences(\n",
        "    sequences,\n",
        "    maxlen=max_sequence_length,\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el embedding matrix de nuestro dataset\n",
        "embedding_matrix = np.ones((vocab_size + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <= vocab_size:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_matrix[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "padded_seq[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el dataset en train (80%) y test (20%) \n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_seq, df['label'], test_size=0.20, random_state=42, stratify=df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uv5NKAmyuPw"
      },
      "source": [
        "## Redes Neuronales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgiVrYgXyuPw"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Embedding, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construir y entrenar la red neuronal\n",
        "model = Sequential()\n",
        "\n",
        "# Capa de Embedding\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim=vocab_size + 1,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_sequence_length,\n",
        "        trainable=True,\n",
        "    )\n",
        ")\n",
        "model.add(LSTM(units=100, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(units=65, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(units=32, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(units=16, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or-fTU1syuPx",
        "outputId": "bbd8aee1-551c-4397-eaaf-928d72ae80ef"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    np.array(X_train),\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=True,\n",
        "    validation_data=(np.array(X_test), y_test),\n",
        "    workers=12\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar el modelo\n",
        "model.save(\"modelo.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ver importancia de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCWG5D064L0i"
      },
      "outputs": [],
      "source": [
        "%pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRdiuk6LyuPx"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "class_names=['NotFake','IsFake']\n",
        "explainer= LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "def predict_proba(data):\n",
        "  list_tokenized_ex = tokenizer.texts_to_sequences(data)\n",
        "  Ex = pad_sequences(list_tokenized_ex, maxlen=max_sequence_length)\n",
        "  pred=model.predict(Ex)\n",
        "  returnable=[]\n",
        "  for i in pred:\n",
        "    temp=i[0]\n",
        "    returnable.append(np.array([1-temp,temp]))\n",
        "  return np.array(returnable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pzin3wcyuPy"
      },
      "outputs": [],
      "source": [
        "print(\"Actual rating\",df['label'][10])\n",
        "explainer.explain_instance(df['features'][10],predict_proba).show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"features\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Frecuencia de Palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=5000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Ahora le solicitamos utilizando nuestro conjunto de datos que construya el vocabulario y tambien transforme nuestro texto\n",
        "texto_features = vectorizer.fit_transform(df[\"features\"])\n",
        "\n",
        "# Obtenemos las palabras y las frecuencias\n",
        "palabras = vectorizer.get_feature_names_out()\n",
        "frecuencias = texto_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sumar las frecuencias de todas las palabras\n",
        "frecuencias_totales = frecuencias.sum(axis=0)\n",
        "\n",
        "# Obtener las palabras más frecuentes y sus frecuencias\n",
        "palabras_mas_frecuentes = [palabras[i] for i in frecuencias_totales.argsort()[::-1][:10]]\n",
        "frecuencias_mas_frecuentes = [frecuencias_totales[i] for i in frecuencias_totales.argsort()[::-1][:10]]\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(palabras_mas_frecuentes, frecuencias_mas_frecuentes, color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('Palabra')\n",
        "plt.title('Palabras más frecuentes')\n",
        "plt.gca().invert_yaxis()  # Invertir el eje y para mostrar las palabras más frecuentes arriba\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNyaYIQJyuPy"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oovCAhafyuP8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLu3qGYtyuP8"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(np.array(X_test), y_test)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzbg7b2gyuP8"
      },
      "outputs": [],
      "source": [
        "# Predecir con el modelo\n",
        "predictions = model.predict(np.array(X_test))\n",
        "\n",
        "# Convertir las probabilidades en clases\n",
        "predictions = list(map(lambda x: 1 if (x > 0.5) else 0, predictions))\n",
        "\n",
        "# Mostrar el reporte de clasificación\n",
        "cm = confusion_matrix(y_test, predictions, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwayw6XkyuP9"
      },
      "outputs": [],
      "source": [
        "# Mostrar el reporte de clasificación\n",
        "print(classification_report(y_test, list(predictions), digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb5NX9v0yuP9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
